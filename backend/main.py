from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from selenium import webdriver
from selenium.webdriver.edge.service import Service
from selenium.webdriver.edge.options import Options
import os
import requests
import datetime
from dotenv import load_dotenv
load_dotenv()

# Import database configuration
try:
    from backend.database_config import DATABASE_URL, test_database_connection
    print(f"Database URL: {DATABASE_URL}")
    # Test database connection on startup
    test_database_connection()
except ImportError as e:
    print(f"Warning: Could not import database configuration: {e}")

# Ensure these imports point to actual router objects
import sys
import os
# Add the current directory to Python path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from backend.router import tool_runner, tools
except ImportError as e:
    try:
        from router import tool_runner, tools
    except ImportError as e2:
        # Fallback if router imports fail
        tool_runner = None
        tools = None
        print("Warning: Could not import router modules")

try:
    import gem_api, eproc_api, admin_metrics_api, analytics_api
except ImportError:
    # Fallback if API imports fail
    gem_api = None
    eproc_api = None
    admin_metrics_api = None
    analytics_api = None
    print("Warning: Could not import API modules")
from supabase import create_client, Client

supabase_url = "https://zjfjaezztfydiryzsyvd.supabase.co"
supabase_key = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InpqZmphZXp6dGZ5ZGlyeXpzeXZkIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTEwMjcwMjEsImV4cCI6MjA2NjYwMzAyMX0.6ZVMwXK4aMGmR68GTYo0yt_L7bOg5QWtElTaa8heQos"
supabase: Client = create_client(supabase_url, supabase_key)

app = FastAPI()

# Configure CORS correctly
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "http://localhost:3000",
        "http://44.244.35.65:3000",
        "http://44.244.35.65",
        "https://lavangam-app-us-west-2.s3-website-us-west-2.amazonaws.com",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include your routers
if tool_runner:
    app.include_router(tool_runner.router)
if tools:
    app.include_router(tools.router)
if gem_api:
    app.mount("/gem", gem_api.app)
if eproc_api:
    app.mount("/eproc", eproc_api.app)
if admin_metrics_api:
    app.mount("/admin", admin_metrics_api.app)
if analytics_api:
    app.mount("/analytics", analytics_api.app)

@app.options('/api/open-chrome')
async def options_open_chrome(_: Request):
    # Explicit preflight support
    return JSONResponse({}, status_code=200)

@app.post('/api/open-chrome')
async def open_chrome(request: Request):
    data = await request.json()
    url = data.get('url')
    if not url:
        return JSONResponse({'error': 'No URL provided'}, status_code=400)
    try:
        from selenium.webdriver.chrome.service import Service as ChromeService
        from selenium.webdriver.chrome.options import Options as ChromeOptions
        from webdriver_manager.chrome import ChromeDriverManager
        import tempfile

        options = ChromeOptions()
        options.add_experimental_option("detach", True)
        options.add_argument("--ignore-certificate-errors")
        options.add_argument("--ignore-ssl-errors")
        options.add_argument("--ignore-certificate-errors-spki-list")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--remote-allow-origins=*")
        options.add_argument("--headless=new")
        options.add_argument(f"--user-data-dir={tempfile.mkdtemp(prefix='chrome-profile-')}")

        service = ChromeService(executable_path=ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)

        driver.get(url)
        return JSONResponse({'status': 'success'}, status_code=200)
    except Exception as e:
        return JSONResponse({'error': f"Failed to open Chrome: {e}"}, status_code=500)

# Backward compatibility: support old /api/open-edge endpoint and CORS preflight
@app.options('/api/open-edge')
async def options_open_edge(_: Request):
    return JSONResponse({}, status_code=200)

@app.post('/api/open-edge')
async def open_edge_compat(request: Request):
    return await open_chrome(request)

@app.post("/api/ai-assistant")
async def ai_assistant(request: Request):
    data = await request.json()
    user_message = data.get("message")
    api_key = os.getenv("GROQ_API_KEY")
    print("API Key:", api_key)  # Debug
    print("User message:", user_message)  # Debug
    if not api_key:
        print("GROQ_API_KEY not set!")  # Debug
        return JSONResponse({"error": "GROQ_API_KEY not set in environment."}, status_code=500)
    try:
        response = requests.post(
            "https://api.groq.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": "llama3-70b-8192",
                "messages": [{"role": "user", "content": user_message}]
            }
        )
        print("Groq response status:", response.status_code)  # Debug
        print("Groq response body:", response.text)  # Debug
        result = response.json()
        return {"response": result["choices"][0]["message"]["content"]}
    except Exception as e:
        print("Exception:", str(e))  # Debug
        return JSONResponse({"error": str(e)}, status_code=500)

@app.get("/api/dashboard-overview")
def dashboard_overview():
    # Example queries - replace with your actual table/column names
    # Active jobs: count where status = 'running'
    active_jobs = supabase.table("jobs").select("id").eq("status", "running").execute().data
    # Completed today: count where status = 'completed' and today
    completed_today = supabase.table("jobs").select("id").eq("status", "completed").gte("completed_at", "2024-07-25").execute().data
    # Total downloads: count from downloads table
    total_downloads = supabase.table("downloads").select("id").execute().data
    # Success rate: percent of jobs with status = 'completed'
    total_jobs = supabase.table("jobs").select("id").execute().data
    success_rate = (len([j for j in total_jobs if j.get('status') == 'completed']) / len(total_jobs) * 100) if total_jobs else 0

    # Weekly activity: mock data for now
    weekly_activity = [
        {"day": "Mon", "value": 12},
        {"day": "Tue", "value": 18},
        {"day": "Wed", "value": 6},
        {"day": "Thu", "value": 12},
        {"day": "Fri", "value": 18},
        {"day": "Sat", "value": 14},
        {"day": "Sun", "value": 10}
    ]
    # Recent activity: last 4 jobs
    recent_activity = supabase.table("jobs").select("status,message,details,created_at").order("created_at", desc=True).limit(4).execute().data
    # System status: mock data for now
    system_status = {
        "apiServer": {"status": "Online", "uptime": 99.9},
        "database": {"status": "Online", "uptime": 99.8},
        "queueSystem": {"status": "Online", "uptime": 99.7}
    }
    return JSONResponse({
        "summary": {
            "activeJobs": len(active_jobs),
            "completedToday": len(completed_today),
            "totalDownloads": len(total_downloads),
            "successRate": round(success_rate, 2),
            "activeJobsDelta": 2,  # Placeholder
            "completedTodayDelta": 18,  # Placeholder
            "totalDownloadsDelta": 5.2,  # Placeholder
            "successRateDelta": 2.1  # Placeholder
        },
        "weeklyActivity": weekly_activity,
        "recentActivity": recent_activity,
        "systemStatus": system_status
    })

@app.get("/main/api/admin/supabase-users")
async def get_supabase_users_main():
    # Use the service role key directly (for admin access)
    service_role_key = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InpqZmphZXp6dGZ5ZGlyeXpzeXZkIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MTAyNzAyMSwiZXhwIjoyMDY2NjAzMDIxfQ.sRbGz6wbBoMmY8Ol3vEPc4VOh2oEWpcONi9DkUsTpKk"
    supabase_url = "https://zjfjaezztfydiryzsyvd.supabase.co"
    try:
        # Create Supabase client with service role key
        from supabase import create_client
        supabase_admin = create_client(supabase_url, service_role_key)
        # Fetch users from Supabase Auth
        response = supabase_admin.auth.admin.list_users()
        if hasattr(response, 'user') and response.user:
            users = response.user
        else:
            # Fallback: try direct API call
            import requests
            url = f"{supabase_url}/auth/v1/admin/users"
            headers = {
                "apikey": service_role_key,
                "Authorization": f"Bearer {service_role_key}",
            }
            api_response = requests.get(url, headers=headers)
            if api_response.status_code != 200:
                print(f"Supabase API error: {api_response.status_code} - {api_response.text}")
                # Return mock data instead of error
                return {
                    "users": [
                        {
                            "id": "mock-user-1",
                            "email": "admin@example.com",
                            "created_at": "2024-01-01T00:00:00Z",
                            "last_sign_in_at": "2024-07-31T12:00:00Z",
                            "role": "admin",
                            "is_active": True,
                        },
                        {
                            "id": "mock-user-2",
                            "email": "user@example.com",
                            "created_at": "2024-01-15T00:00:00Z",
                            "last_sign_in_at": "2024-07-30T10:30:00Z",
                            "role": "user",
                            "is_active": True,
                        }
                    ]
                }
            users = api_response.json().get("users", [])
        # Format user data
        user_list = [
            {
                "id": user.get("id"),
                "email": user.get("email"),
                "created_at": user.get("created_at"),
                "last_sign_in_at": user.get("last_sign_in_at"),
                "role": user.get("role", "user"),
                "is_active": user.get("email_confirmed_at") is not None,
            }
            for user in users
        ]
        return {"users": user_list}
    except Exception as e:
        print(f"Error fetching Supabase users: {str(e)}")
        # Return mock data instead of error
        return {
            "users": [
                {
                    "id": "mock-user-1",
                    "email": "admin@example.com",
                    "created_at": "2024-01-01T00:00:00Z",
                    "last_sign_in_at": "2024-07-31T12:00:00Z",
                    "role": "admin",
                    "is_active": True,
                },
                {
                    "id": "mock-user-2",
                    "email": "user@example.com",
                    "created_at": "2024-01-15T00:00:00Z",
                    "last_sign_in_at": "2024-07-30T10:30:00Z",
                    "role": "user",
                    "is_active": True,
                },
                {
                    "id": "mock-user-3",
                    "email": "test@example.com",
                    "created_at": "2024-02-01T00:00:00Z",
                    "last_sign_in_at": "2024-07-29T15:45:00Z",
                    "role": "user",
                    "is_active": False,
                }
            ]
        }

# Export endpoints
@app.get("/api/export-data")
async def export_user_data(request: Request):
    """Export all user data as JSON"""
    try:
        # Get user ID from request (you might need to implement proper auth)
        # For now, we'll export all data
        user_id = "all"  # This should come from authentication
        
        # Get user profile data from Supabase
        try:
            users_response = supabase.table("users").select("*").execute()
            users_data = users_response.data if users_response.data else []
        except Exception as e:
            print(f"Supabase users error: {e}")
            users_data = []
        
        # Get scraping jobs from Supabase
        try:
            jobs_response = supabase.table("jobs").select("*").execute()
            jobs_data = jobs_response.data if jobs_response.data else []
        except Exception as e:
            print(f"Supabase jobs error: {e}")
            jobs_data = []
        
        # Get available output files information
        output_dirs = ['gem', 'ireps', 'eproc', 'ap']
        available_files = []
        
        for dir_name in output_dirs:
            output_path = f"outputs/{dir_name}"
            if os.path.exists(output_path):
                try:
                    files = os.listdir(output_path)
                    for file in files:
                        file_path = os.path.join(output_path, file)
                        if os.path.isdir(file_path):
                            sub_files = os.listdir(file_path)
                            available_files.append({
                                "tool": dir_name.upper(),
                                "sessionId": file,
                                "files": [f for f in sub_files if f.endswith(('.xlsx', '.csv'))],
                                "path": f"outputs/{dir_name}/{file}"
                            })
                except Exception as e:
                    print(f"Error reading directory {output_path}: {e}")
        
        # Prepare export data
        export_data = {
            "exportDate": str(datetime.datetime.now()),
            "user": users_data[0] if users_data else None,
            "scrapingJobs": jobs_data,
            "availableFiles": available_files,
            "summary": {
                "totalJobs": len(jobs_data),
                "completedJobs": len([j for j in jobs_data if j.get('status') == 'completed']),
                "failedJobs": len([j for j in jobs_data if j.get('status') == 'failed']),
                "runningJobs": len([j for j in jobs_data if j.get('status') == 'running']),
                "totalOutputFiles": sum(len(dir_info['files']) for dir_info in available_files),
                "availableSessions": len(available_files)
            }
        }
        
        return JSONResponse(export_data)
        
    except Exception as e:
        print(f"Export data error: {str(e)}")
        return JSONResponse({"error": "Failed to export data"}, status_code=500)

@app.get("/api/export-files")
async def export_output_files(request: Request):
    """Export all output files as ZIP"""
    try:
        import zipfile
        import io
        
        # Create a ZIP file in memory
        zip_buffer = io.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # Add output directories to the zip
            output_dirs = ['gem', 'ireps', 'eproc', 'ap']
            has_files = False
            
            for dir_name in output_dirs:
                output_path = f"outputs/{dir_name}"
                if os.path.exists(output_path):
                    try:
                        files = os.listdir(output_path)
                        if files:
                            # Add the entire directory to the zip
                            for root, dirs, files in os.walk(output_path):
                                for file in files:
                                    file_path = os.path.join(root, file)
                                    arc_name = os.path.relpath(file_path, "outputs")
                                    zip_file.write(file_path, arc_name)
                                    has_files = True
                    except Exception as e:
                        print(f"Error adding directory {output_path} to zip: {e}")
            
            if not has_files:
                # If no files found, create an empty zip with a readme
                zip_file.writestr("README.txt", "No output files found at the time of export.")
        
        # Prepare response
        zip_buffer.seek(0)
        
        from fastapi.responses import StreamingResponse
        return StreamingResponse(
            io.BytesIO(zip_buffer.getvalue()),
            media_type="application/zip",
            headers={"Content-Disposition": f"attachment; filename=output_files_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"}
        )
        
    except Exception as e:
        print(f"Export files error: {str(e)}")
        return JSONResponse({"error": "Failed to export files"}, status_code=500)

if __name__ == "__main__":
    import uvicorn
    print("🚀 Starting Admin Panel Backend Server on port 8000...")
    print("📡 API will be available at: http://44.244.35.65:8000")
    print("👥 Supabase users endpoint: http://44.244.35.65:8000/api/admin/supabase-users")
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)